\documentclass[12pt,a4paper]{article}

% Packages

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%% Layout
\usepackage[a4paper,margin=2.5cm]{geometry}
\usepackage{parskip}

%% Fonts
\usepackage{bm}
\usepackage{microtype}
\usepackage{mathrsfs}
\usepackage{lmodern}

%% Core math
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}

%% Useful math
\usepackage{mathdots}
\usepackage{cool}

%% Algorithms and code
\usepackage{algorithm2e}
\usepackage{listings}
\usepackage{lstlang0}

%% Graphics
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows,calc,decorations.markings,cd}

%% Linking and numbering
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}

%% References
\usepackage[
backend=bibtex,
style=alphabetic,
sorting=ynt
]{biblatex}

\addbibresource{report.bib}

% Useful commands and definitions

%% Fix spacing between theorems due to parskip

\makeatletter
\def\thm@space@setup{%
  \thm@preskip=\parskip \thm@postskip=0pt
}
\makeatother

%% Listings style

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
  basicstyle=\footnotesize\ttfamily,            % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

%% The standard sets of numbers
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}

%% \abs{} and \norm{} give absolute value and norm respectively
%% \abs*{} and \norm*{} give versions which resize
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}

\DeclareMathOperator{\Mor}{Mor}
\DeclareMathOperator{\Map}{Map}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\lcm}{lcm}
\makeatletter
\newcommand*{\bdiv}{%
  \nonscript\mskip-\medmuskip\mkern5mu%
  \mathbin{\operator@font div}\penalty900\mkern5mu%
  \nonscript\mskip-\medmuskip
}
\makeatother

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}

\title{Computation with Finitely Generated Abelian Groups}
\author{Peter Huxford}

\begin{document}

\maketitle

\begin{abstract}
  The aim of this report is to better understand the theory of finitely generated abelian groups, and computational methods pertaining to them. We shall see that an important tool is the \emph{Smith Normal Form} of an integer matrix.

Naive methods inspired by Gaussian elimination to compute the Smith Normal Form of a matrix can require arbitrary precision arithmetic for small inputs. We will explore some useful techniques, which allow us to perform calculations with respect to an appropriate modulus.
\end{abstract}

\section{Preliminaries}

In these notes, we will always write the group operation of an abelian group additively, unless otherwise stated. 

\begin{definition}[Universal Property]
  A group $G$ is \emph{free abelian} on a subset $X\subseteq G$ if every map from $X$ to an abelian group $H$ extends to a unique homomorphism $G\to H$. We call $X$ a \emph{basis} for $G$ if $G$ is free abelian on $X$.
\end{definition}

There is a similarity with vector spaces: $B$ is a basis of a vector space $V$ if and only if every map from $B$ to a vector space $W$ extends uniquely to a linear map $V\to W$. The existence of such a linear map is equivalent to $B$ being a linearly independent set, and the uniqueness is equivalent to $B$ spanning $V$.


\begin{theorem}
  The free abelian groups with finite basis, up to isomorphism, consist of the groups $\Z^n$ for $n\in\N$.
\end{theorem}

\begin{proof}
  Let $e_i\in\Z^n$ be the $i$th standard basis vector. Each element of $\Z^n$ takes the form $m_1e_1+\cdots m_ne_n$, for unique integers $m_i\in\Z$. Given a map from $\{e_1,\ldots,e_n\}$ to a group $H$, we can extend it to a group homomorphism $\Z^n\to H$ as follows. If $e_i\mapsto h_i$, then define
  \[ m_1e_1 + \cdots + m_ne_n \mapsto m_1h_1 + \cdots + m_nh_n. \]
  It is readily seen that this defines a group homomorphism from $\Z^n$ to $H$, sending $e_i\mapsto h_i$. Moreover each group homomorphism $\Z^n\to H$ which maps $e_i\mapsto h_i$ must agree with this. Hence $\Z^n$ is free abelian on $\{e_1,\ldots,e_n\}$.

  Conversely, suppose that $G$ is free abelian on $X=\{x_1,\ldots,x_n\}$. By the universal property, we obtain a homomorphism $\phi\colon G\to\Z^n$ which maps $x_i\mapsto e_i$. Similarly we have a homomorphism $\psi\colon\Z^n\to G$ which maps $e_i\mapsto x_i$. Then $\psi\circ\phi$ is an endomorphism of $G$ fixing $X$. By the uniqueness in the universal property, $\psi\circ\phi$ must be the identity on $G$. Similarly $\phi\circ\psi$ is the identity on $\Z^n$. Hence $G\cong\Z^n$.
\end{proof}

Let $G$ be an abelian group generated by $n$ elements. Since $\Z^n$ is free abelian there is an epimorphism $\Z^n\twoheadrightarrow G$ with kernel $H$. By the first isomorphism theorem, $\Z^n/H$ is isomorphic to $G$. Thus understanding the structure of subgroups of $\Z^n$ will give us insight into the structure of finitely generated abelian groups.

\begin{theorem}[Dedekind]
  A subgroup of $\Z^n$ can be generated by at most $n$ elements.
\end{theorem}

\begin{proof}
  We proceed by induction on $n$. Defining $\Z^0\coloneqq\{0\}$, the case $n=0$ becomes trivial. Let $n>0$, and let $\varphi\colon\Z^n\twoheadrightarrow\Z^n/\langle e_n \rangle$ be the natural map. Note that $\Z^n/\langle e_n \rangle\cong\Z^{n-1}$. If $H\leq\Z^n$, then $\varphi(H)$ is isomorphic to a subgroup of $\Z^{n-1}$. Inductively, we may assume $\varphi(H)=\langle h_1 + \langle e_n \rangle, \ldots, h_{n-1} + \langle e_n \rangle \rangle$, for $h_i\in H$. Note that $H\cap\langle e_n \rangle$ is cyclic, so let $H\cap\langle e_n \rangle=\langle h_n \rangle$ for some $h_n\in H$. We claim $H=\langle h_1,\ldots,h_n \rangle$.

  If $h\in H$, then $\varphi(h)=h'+\langle e_n \rangle$ for some $h'\in\langle h_1,\ldots,h_{n-1} \rangle$. Now $h-h'\in H\cap\langle e_n \rangle=\langle h_n \rangle$. Thus $h\in\langle h_1,\ldots,h_n \rangle$, and hence $H=\langle h_1,\ldots,h_n \rangle$. By induction the theorem follows.
\end{proof}

\begin{definition}
  The \emph{integer row space} of an $m\times n$ integer matrix $A$ is $S(A)\coloneqq\{xA : x\in\Z^m\}$, i.e. the set of all integral linear combinations of rows of $A$.
\end{definition}

If $H=\langle h_1,\ldots,h_m \rangle\leq\Z^n$, then $H$ consists of all integral linear combinations of the $h_i$. Hence each finitely generated abelian group is isomorphic to $\Z^n/S(A)$ for some $m\times n$ integer matrix $A$. For most descriptions of finitely generated abelian groups, we can explicitly find such an $A$. For example, consider the abelianisation $G_{ab}\coloneqq G/[G,G]$ of a finitely presented group $G$.

If $G=\langle X \mid R \rangle$ is a finite presentation, then the abelianisation $G_{ab}$ is a finitely generated abelian group, with presentation $\langle X \mid R, [X,X] \rangle$. If $X=\{x_1,\ldots,x_n\}$, then we can rewrite each of the relations in $R$ in the form $x_1^{\alpha_1}\cdots x_n^{\alpha_n}$, $\alpha_i\in\Z$. The epimorphism $\Z^n\twoheadrightarrow G_{ab}$ sending $e_i\mapsto x_i$ has kernel generated by the $(\alpha_1,\ldots,\alpha_n)$ appearing in the relations. Using these rows we can form a ``relation matrix'' $A$, and then $G_{ab}\cong\Z^n/S(A)$.

\section{Integer Row Reduction}

A notion of row space can be defined for matrices over an arbitrary ring. When working over a field, we can apply row operations to produce a matrix in reduced row echelon form (e.g. using Gaussian elimination). We develop a similar theory for integer matrices below.

\begin{definition}
  An \emph{integer row operation} applied to a matrix is one of the following:
  \begin{enumerate}
  \item Swap two rows.
  \item Multiply a row by $-1$.
  \item Add an integer multiple of one row to another row.
  \end{enumerate}
  Two $m\times n$ integer matrices $A$ and $B$ are \emph{row equivalent} if there is a sequence of integer row operations transforming one into the other, and we write $A\sim B$.
\end{definition}

We can reverse each integer row operation with another. The first two types are involutions. To reverse adding $q$ times row $i$ to row $j$, for $i\neq j$, we add $-q$ times row $i$ to row $j$. This makes $\sim$ an equivalence relation on integer $m\times n$ matrices.

In the above definition rows may only be multiplied by $-1$, in contrast to row operations over a field, where rows may be multiplied by an arbitrary non-zero scalar. This is because multiplying a row by a scalar can be reversed when multiplying by a unit, and the units of a field are its non-zero elements, but the units of $\Z$ are just $1$ and $-1$.

\begin{theorem}
  If $A$ and $B$ are integer matrices with $A\sim B$, then $S(A)=S(B)$.
\end{theorem}

\begin{proof}
  If $B$ is obtained from $A$ by a single integer row operation, then the rows of $B$ are clearly in $S(A)$, so $S(B)\subseteq S(A)$. Moreover this row operation can be reversed, thus $S(A)\subseteq S(B)$. Therefore $A\sim B\implies S(A)=S(B)$.
\end{proof}

The corresponding notion of reduced row echelon form for integer matrices is row Hermite Normal Form (HNF).

\begin{definition}
  An integer $m\times n$ matrix $A$ is in \emph{row Hermite Normal Form (HNF)} if
  \begin{enumerate}
  \item The nonzero rows of $A$ are the first $r$ rows of $A$, for some $r\leq m$.
  \item If $j_i$ is minimal with $A_{i,j_i}$ nonzero, for $1\leq i\leq r$, then $j_1<j_2<\cdots<j_r$.
  \item If $1\leq i\leq r$, then $A_{i,j_i}>0$.
  \item If $1\leq k<i\leq r$, then $0\leq A_{k,j_i}<A_{i,j_i}$.
  \end{enumerate}
\end{definition}

In the above definition, the entries $A_{i,j_i}$ behave similarly to the pivot entries in reduced row echelon form. Below is a sample matrix in row Hermite Normal Form.
\[ A \coloneqq
  \begin{bmatrix}
    2 & 1 & 2 & 3 \\
    0 & 0 & 7 & 5 \\
    0 & 0 & 0 & 9
  \end{bmatrix}.
\]

Suppose we want to determine whether a given $u\in\Z^4$ is in $S(A)$. For instance, let $u=(4,2,-3,10)$. We seek $x,y,z\in\Z$ with $u=xa_1+ya_2+za_3$, where $a_1,a_2,a_3$ are the rows of $A$. Isolating the first column, we see $4=2x$, so $x=2$. Next set $v=u-2a_1=(0,0,-7,4)$. We require $v=ya_2+za_3$. The second column holds no information. The third column tells us that $-7=7y$, so $y=-1$. Set $w=v+a_2=(0,0,0,9)$. We require $w=za_3$. Observing the last column shows $9=9z$, so $z=1$. Hence $u=2a_1-a_2+a_3$, and so $u\in S(A)$.

If at any stage we found an equation that was not solvable for integer $x,y,z$, then we would instead conclude that $u\notin S(A)$. Clearly, testing membership in $S(A)$ is easy when $A$ is in HNF. One can also show the nonzero rows of $A$ form a basis of $S(A)$ when $A$ is in HNF.

\begin{theorem}
  If $A$ is an $m\times n$ integer matrix, then there is a unique $m\times n$ integer matrix $B$ with $A\sim B$ and $B$ in row Hermite Normal Form.
\end{theorem}

\begin{proof}
  We prove this by induction. The result holds trivially when $m=0$ or $n=0$. Suppose that $m,n\geq1$, and that the result holds for all smaller matrices. If there are two nonzero entries in the first column, say $0<\abs{A_{k,1}}\leq\abs{A_{\ell.1}}$ with $k\neq\ell$, then we decrease the quantity $\abs{A_{1,1}}+\cdots+\abs{A_{m,1}}$ as follows.

  First multiply rows $k,\ell$ by $-1$ if necessary so that $A_{k,1},A_{\ell,1}>0$. Next, subtract row $k$ away from row $\ell$. Since $0\leq A_{\ell,1}-A_{k,1}<A_{\ell,1}$, this strictly decreases the quantity $\abs{A_{1,1}}+\cdots+\abs{A_{m,1}}$. This quantity is a non-negative integer, so it can only be decreased finitely many times. Hence we may assume that $A$ has at most one nonzero entry in the first column. If all entries in the first column are zero, then $A$ has the block form

  \[ A = \left[
      \begin{array}{c|ccccc}
        0 &&&&& \\
        \vdots &&& A' && \\
        0 &&&&& \\
      \end{array}\right]
  \]

  By induction we can reduce $A'$ to HNF by row operations, thus we can reduce $A$ to HNF by row operations. Suppose that $A$ has only one nonzero entry in the first column. By swapping rows and multiplying by $-1$ if necessary, we may assume that the nonzero entry is $A_{1,1}$ and $A_{1,1}>0$. Now $A$ has the block form
  \[ A = \left[
      \begin{array}{c|ccccc}
        A_{1,1} & A_{1,2} && \cdots && A_{1,n} \\
        \hline
        0 &&&&& \\
        \vdots &&& A' && \\
        0 &&&&& \\
      \end{array}\right]
  \]
  By induction we can reduce $A'$ to HNF by row operations, so we may assume that $A'$ is in HNF. Suppose that the nonzero rows of $A$ are now the first $r$ rows, and that the first nonzero entry in each row is given by $A_{i,j_i}$, for $1\leq i\leq r$. Let $2\leq k\leq r$, and suppose we have already arranged for $0\leq A_{1,j_i}<A_{i,j_i}$ to hold, for each $i=2,\ldots,k-1$.

  Using the division algorithm we may write $A_{1,j_k}=qA_{k,j_k}+r$, where $0\leq r<A_{k,j_k}$. We subtract $q$ times row $k$ away from row 1. Because $A_{k,j_k}$ is the first nonzero entry in row $k$, and $1=j_1<j_2<\cdots<j_k$, we still have $0\leq A_{1,j_i}<A_{i,j_i}$ for each $i=2,\ldots,k-1$.

  Hence by induction we can reduce $A$ to some matrix $B$ in HNF, by integer row operations. Let $B'$ be another matrix for which $A\sim B'$ and $B'$ is in HNF. Let $b_1,\ldots,b_m$ and $b_1',\ldots,b_m'$ be the rows of $B$ and $B'$ respectively. If $B\neq B'$, then there are entries with $B_{i,j}\neq B'_{i,j}$. Choose such $i,j$ with $j$ minimal, without loss of generality $B_{i,j}>B_{i,j}'$. We have $b_i,b_i'\in S(B)=S(A)=S(B')$, hence $b_i-b_i'\in S(B)$.

  Suppose that only the first $r$ rows of $B$ are nonzero, and let $B_{i,j_i}$ be the first nonzero entry in $b_i$ for $1\leq i\leq r$. The first $j-1$ entries of $b_i-b_i'$ are zero, so $b_i-b_i'$ is an integral linear combination of the rows $b_k$ with $j_k\geq j$. However $b_{ij}-b_{ij}'\neq0$, and so we must have $j_k=j$ for some $k$ and $B_{k,j}\mid B_{i,j}-B_{i,j}'$. Since $0\leq B_{i,j}'< B_{i,j}<B_{k,j}$, we must have $\abs{B_{i,j}-B_{i,j}'}<B_{k,j}$, so $B_{i,j}-B_{i,j}'=0$, which is a contradiction. Therefore $B=B'$, and so each integer matrix $A$ is row equivalent to a unique integer matrix $B$ in HNF.
\end{proof}

\begin{corollary}
  Let $A,B$ be integer matrices. Then $S(A)=S(B)\implies A\sim B$.
\end{corollary}

\begin{proof}
  It suffices to prove that if $A$ and $B$ are in HNF, then $S(A)=S(B)\implies A=B$. We refer the reader to \cite{sims} for the proof of this.
\end{proof}

The proof of this theorem is readily turned into an procedure, e.g. this one (from \cite{sims})

\begin{algorithm}[H]
  \SetKwInOut{Procedure}{Procedure}
  \Procedure{ROW\_REDUCE(\textasciitilde$A$);}
  \KwIn{An $m\times n$ integer matrix $A$}
  \KwResult{Integer row operations are applied to $A$ to reach row Hermite Normal Form}

  $A\coloneqq B$; $i\coloneqq1$; $j\coloneqq1$;

  \While{$i\leq m$ and $j\leq n$}{
    \eIf{$A_{k,j}=0$ for $i\leq k\leq m$}{$j\coloneqq j+1$}{
      \While{there exist distinct $k,\ell$ with $i\leq k,\ell\leq m$ and $0<\abs{A_{k,j}}\leq\abs{A_{\ell,j}}$}{
        $q\coloneqq A_{\ell,j} \bdiv A_{k,j}$\;
        Subtract $q$ times row $k$ of $A$ from row $\ell$
      }
      Let $A_{kj}\neq0$ with $i\leq k\leq m$; (this $k$ is unique)\\
      \If{$k\neq i$}{swap rows $i$ and $k$ of $A$}
      \If{$A_{i,j}<0$}{multiply row $i$ of $A$ by $-1$}
      \For{$\ell\coloneqq 1$ to $i-1$}{
        $q\coloneqq A_{\ell,j} \bdiv A_{i,j}$\;
        Subtract $q$ times row $i$ of $A$ from row $\ell$
      }
      $i\coloneqq i+1$; $j\coloneqq j+1$\;
    }
  }
\end{algorithm}

There is some freedom when implementing the above algorithm. In the inner while loop, we must select which indices $k,\ell\geq i$ are selected with $0<\abs{A_{k,j}}\leq\abs{A_{\ell,j}}$. If $k,\ell$ are chosen so that $\abs{A_{\ell,j}}-\abs{A_{k,j}}$ is maximized, then that the quantity $\abs{A_{1,j}}+\cdots+\abs{A_{m,j}}$ decreases as much as possible in each iteration. As described in the second paragraph of the previous proof, the condition in this while loop no longer holds when this quantity can no longer decrease. Thus one might expect this strategy to be the most efficient.

In practice one finds that this strategy can result in $A$ having large entries, significantly increasing run time. This issue is discussed in \cite{rosser}, where an alternate strategy is proposed. The \emph{Rosser strategy} is to choose $k,\ell$ so that $\abs{A_{\ell,j}}$ is as large as possible, and $\abs{A_{k,j}}$ is as large as possible with $k\neq\ell$. Many authors recommend this because it tends to keep the size of the entries small during the procedure. See \autoref{hnfcode} for a {\sc Magma} implementation of the row reduction algorithm employing this strategy.

\section{Smith Normal Form}
\label{snf-discussion}

In the previous section we showed that integer row operations applied to an $m\times n$ matrix $A$ do not change $S(A)$. We prove further that column operations do not affect the isomorphism type of $\Z^n/S(A)$.

\begin{definition}
  An \emph{integer column operation} applied to a matrix is one of the following:
  \begin{enumerate}
  \item Swap two columns.
  \item Multiply a row by $-1$.
  \item Add an integer multiple of one column to another column.
  \end{enumerate}
\end{definition}

\begin{definition}
  Two $m\times n$ integer matrices $A$ and $B$ are \emph{equivalent} if there is a sequence of integer row and column operations transforming one into the other, and we write $A\approx B$.
\end{definition}

\begin{theorem}
  If $A,B$ are $m\times n$ integer matrices, then $A\approx B$ if and only if there exist matrices $P\in\GL_m(\Z)$ and $Q\in\GL_n(\Z)$ such that $B=PAQ$.
\end{theorem}

\begin{proof}
  For each integer row operation on an $m\times n$ matrix, there is a corresponding matrix $P\in\GL_m(\Z)$ such that the effect of applying the row operation is equivalent to left multiplication by $P$. Moreover these ``elementary'' matrices generate $\GL_m(\Z)$. Similarly integer column operations correspond to right multiplication by matrices in $\GL_n(\Z)$.
\end{proof}

\begin{theorem}
  \label{commutative-diagram}
  Let $A,B$ be integer $m\times n$ matrices. Then $A\approx B\implies \Z^n/S(A)\cong\Z^n/S(B)$.
\end{theorem}

\begin{proof}
  There exist $P\in\GL_m(\Z)$, $Q\in\GL_n(\Z)$ such that $B=PAQ$. Then $B\sim AQ$, hence $S(B)=S(AQ)$. Notice that $S(A)Q\coloneqq\{uQ : u\in S(A)\}=\{xAQ : x\in\Z^m\}=S(AQ)$. It follows that the mapping illustrated in the diagram is a well defined homomorphism $\Z^n/S(A)\to\Z^n/S(AQ)=\Z^n/S(B)$. It is an isomorphism because $Q$ is invertible.

  \centering
  \begin{tikzcd}
    \Z^n \arrow[rrr, "Q\colon x\;\mapsto\; xQ"] \arrow[dd, two heads] & & & \Z^n \arrow[dd, two heads] \\
    & & &  \\
    \Z^n/S(A) \arrow[rrr, "x + S(A)\; \mapsto\;  xQ + S(AQ)"'] & & & \Z^n/S(AQ)
  \end{tikzcd}

\end{proof}

We establish a normal form which distinguishes the isomorphism types of $\Z^n/S(A)$.

\begin{definition}
  An $m\times n$ integer matrix $A$ is in \emph{Smith Normal Form (SNF)} if there is some $r$ such that $d_i\coloneqq A_{i,i}>0$ for each $1\leq i\leq r$, all remaining entries of $A$ are zero, and $d_1\mid d_2\mid \cdots \mid d_r$. The integers $d_1,\ldots,d_r$ are the \emph{invariant factors} of $A$.
\end{definition}

Here is a sample matrix in Smith Normal Form
\[ A \coloneqq
  \begin{bmatrix}
    2 & 0 & 0 & 0 & 0 \\
    0 & 4 & 0 & 0 & 0 \\
    0 & 0 & 12 & 0 & 0
  \end{bmatrix}.
\]
Note that $S(A)=\{(2x,4y,12z,0,0) : x,y,z\in\Z\}$. This is the kernel of the epimorphism
\begin{align*}
  \Z^5 &\twoheadrightarrow \Z_2\oplus\Z_4\oplus\Z_{12}\oplus\Z\oplus\Z \\
  (a,b,c,d,e) &\mapsto (a\bmod 2, b\bmod 4, c\bmod 12, d, e).
\end{align*}
Therefore $\Z^5/S(A)\cong\Z_2\oplus\Z_4\oplus\Z_{12}\oplus\Z\oplus\Z$. Determining the isomorphism type of $\Z^n/S(A)$ for an $m\times n$ matrix $A$ is simple when $A$ is in Smith Normal Form.

\begin{theorem}
  \label{decomposition}
  Let $A$ be an $m\times n$ integer matrix in SNF, with invariant factors $d_1,d_2,\ldots,d_r$. Then $\Z^n/S(A)\cong\Z_{d_1}\oplus\cdots\oplus\Z_{d_r}\oplus\Z^{n-r}$.
\end{theorem}

\begin{theorem}
  \label{SNF-existence}
  If $A$ is an integer matrix, then there exists an integer matrix $B$ with $A\approx B$ and $B$ in Smith Normal Form.
\end{theorem}

\begin{proof}
  Suppose $A$ is not the zero matrix. The first goal is to reduce $A$ to the block form
  \[ \left[
    \begin{array}{c|ccc}
      d & 0 & \cdots & 0 \\
      \hline
      0 & & & \\
      \vdots & & A' & \\
      0 & & & \\
    \end{array}\right] \tag{$\star$}
  \]
  with $d>0$. Let $A_{i,j}$ be a nonzero entry of $A$. Swap rows $i$ and 1, and columns $j$ and 1 if required, to ensure $i=j=1$, and multiply row 1 by $-1$ if necessary to ensure $A_{1,1}>0$. If $A_{1,1}$ divides all entries in row and column 1, then add multiples of row/column 1 to the other rows/columns, to reach the form ($\star$).

  If $A_{1,1}$ does not divide all entries in row and column 1, then we decrease this entry as follows. Suppose that $A_{1,1}\nmid A_{i,1}$ for some $i$. Write $A_{i,1}=qA_{1,1}+r$ with $0<r<A_{1,1}$. Then add $-q$ times row 1 to row $i$, and swap rows 1 and $i$. Similarly, if $A_{1,1}\nmid A_{1,j}$ for some $j$, then write $A_{1,j}=qA_{1,1}+r$ with $0<r<A_{1,1}$. Then add $-q$ times column 1 to column $j$, and swap columns 1 and $j$.

  Therefore, after repeating this enough times, we ensure $A_{1,1}$ divides all entries in row and column 1, and thus we can reach the block form ($\star$). Inductively, we can reduce $A'$ to SNF by row and column operations, so we can reduce $A$ to a matrix with block form
  \[ \left[
      \begin{array}{ccc|cc}
        d_1 &&&& \\
            & \ddots &&& 0 \\
            && d_r && \\
        \hline
            &&&& \\
        & 0 &&& 0 \\
      \end{array}\right]
  \]
  where $d_i>0$. If the divisibility condition $d_1\mid d_2\mid\cdots\mid d_r$ holds, then we have produced a matrix in SNF. If not, suppose that $d_i\nmid d_j$ for some $i<j$. Set $a\coloneqq d_i$ and $b\coloneqq d_j$. The Euclidean algorithm produces integers $u,v$ with $d\coloneqq\gcd(a,b)=ua+vb$, and then $\ell\coloneqq\lcm(a,b)=ab/d$. Now
  \[
    \begin{bmatrix}
      u & v \\
      -b/d & a/d
    \end{bmatrix}
    \begin{bmatrix}
      a & 0 \\
      0 & b
    \end{bmatrix}
    \begin{bmatrix}
      1 & -vb/d \\
      1 & ua/d
    \end{bmatrix}
    =
    \begin{bmatrix}
      d & 0 \\
      0 & \ell
    \end{bmatrix}.
  \]
  In this way, we can use row and column operations to replace $d_i$ and $d_j$ with $\gcd(d_i,d_j)$ and $\lcm(d_i,d_j)$ respectively. Repeating this will produce a matrix in Smith Normal Form.
\end{proof}

Uniqueness follows from the uniqueness of the integers in the following important theorem. Note that the previous result implies the existence of such integers. To prove the uniqueness, we refer the reader to \cite{dummit}.

\begin{theorem}[Fundamental Theorem of Finitely Generated Abelian Groups]
  \label{FToFGAG}
  Let $G$ be a finitely generated abelian group. Then there exists unique integers $n,d_1,\ldots,d_r>0$ with $d_1\mid d_2\mid\cdots\mid d_r$, and
  \[ G\cong\Z_{d_1}\oplus\cdots\oplus\Z_{d_r}\oplus\Z^{n-r}. \]
\end{theorem}

\begin{corollary}
  \label{unique-snf}
  If $A$ is an $m\times n$ integer matrix, then there is a unique $m\times n$ integer matrix $B$ with $A\approx B$ and $B$ in Smith Normal Form.
\end{corollary}

Thus it makes sense to define the \emph{invariant factors} of an integer matrix to be the invariant factors of the matrix equivalent to it which is in SNF.

\begin{corollary}
  If $A$ and $B$ are $m\times n$ integer matrices with $\Z^n/S(A)\cong\Z^n/S(B)$, then $A\approx B$.
\end{corollary}

\begin{proof}
  By \autoref{FToFGAG}, $A$ and $B$ have the same invariant factors. Because they have the same dimensions, they must be equivalent to the same matrix in SNF. Hence $A\approx B$.
\end{proof}

The proof of \autoref{SNF-existence} is readily transformed into a procedure for computing the Smith Normal Form of a given matrix. See \autoref{snfcode} for a {\sc Magma} implementation. However one quickly finds that it has certain defects. For example, I ran the implementation in \autoref{snfcode} on a random $100\times 100$ matrix with entries in $\{-1,0,1\}$, on the machine described in \autoref{conclusion}. After 13 hours the procedure had still not terminated. We investigate what happens with a smaller example. Consider the following matrix

\[
  A\coloneqq\begin{bsmallmatrix}
    6 & 9 & 8 & 2 & 6 & 5 & 2 & 0 \\
    5 &10 & 1 & 4 & 8 & 5 & 4 & 8 \\
    3 & 1 & 9 & 6 & 3 &10 & 5 & 3 \\
    6 &10 & 3 & 2 & 5 & 0 & 3 &10 \\
    6 & 1 & 3 & 8 & 6 & 6 & 9 & 1 \\
    6 & 2 & 2 & 1 & 8 & 1 &10 &10 \\
    4 & 4 &10 & 7 &10 & 8 & 3 & 3 \\
    7 & 0 & 1 & 9 & 8 & 5 & 5 & 1 \\
  \end{bsmallmatrix}
\]

If we run the {\sc Magma} implementation given in \autoref{snfcode} on $A$, we find that the intermediate matrix in which the entry with largest modulus appears, is
\[
  \begin{bsmallmatrix}
    1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 1 & 48829330326663043031960 & -769507651269581073 \\
    0 & 0 & 0 & 0 & 0 & 0 & -97658660653326086254291 & 1539015302539162149 \\
    0 & 0 & 0 & 0 & 0 & 0 & 9403552434308768827094970352 & -148191783481495923038334 \\
  \end{bsmallmatrix}
\]
The SNF of $A$ is given by
\[
  \begin{bsmallmatrix}
    1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 10615254 \\
  \end{bsmallmatrix}
\]
The entries of $A$ initially all have modulus at most 10. However intermediate matrices appear with entries of modulus roughly $9.4\times10^{27}$, much larger than any of the entries in the resulting SNF. This ``entry explosion'' is only worsened by increasing the dimensions of the input matrix, and increasing the size of its entries. Arithmetic with entries so large is expensive, so circumventing this issue is of great importance if one wishes to compute the SNF of larger matrices in reasonable time.

\section{Modular techniques}
\label{modular-discussion}

The methods discussed in the previous section to compute Smith Normal Form are inadequate for large matrices. It is not hard to modify the code provided to keep track of the maximum modulus entry.  I constructed a random $100\times100$ matrix whose entries were initially in $\{-1,0,1\}$. After 13 hours of running on the university's servers it has still not terminated. 

The built in {\sc Magma} function \texttt{SmithForm} has no issues computing the Smith Normal Form of such a matrix. This is an indication that the approach taken earlier can be improved. We discuss some ideas described in \cite{sims}, which is heavily inspired by \cite{havas}, which aim to reduce the maximum modulus entry of matrices produced along the way.

We first redevelop some of the theory from the previous sections, modulo a fixed integer. Many of the proofs of the following theorems are similar to ones already given, so we omit them. More detail can be found in \cite{sims}. Fix an integer $d>1$. We use the notation $\overline{A}$ to denote the matrix $A$ with entries reduced modulo $d$.

\begin{definition}
  A \emph{row operation modulo $d$} applied to an integer matrix is one of the following:
  \begin{enumerate}
  \item Swap two rows.
  \item Multiply a row by an integer $c$ with $\gcd(c,d)=1$, reducing entries modulo $d$.
  \item Add an integral multiple of one row to another row, reducing entries modulo $d$.
  \end{enumerate}
  We define \emph{column operations modulo $d$} in a similar fashion. Two $m\times n$ integer matrices $A$ and $B$ are \emph{row equivalent modulo $d$} if there is a sequence of row operations modulo $d$ transforming $\overline{A}$ to $\overline{B}$, and they are \emph{equivalent modulo $d$} if there is a sequence of row and column operations modulo $d$ transforming $\overline{A}$ to $\overline{B}$.
\end{definition}

\begin{definition}
  An integer matrix $A$ is in \emph{row Hermite Normal Form modulo $d$ (HNF modulo $d$)} if
  \begin{enumerate}
  \item $A=\overline{A}$.
  \item $A$ is in row Hermite Normal Form.
  \item The first nonzero entry in each nonzero row divides $d$.
  \end{enumerate}
\end{definition}

Notice that when we work modulo a prime $p$, the third condition ensures that the first nonzero entry in each nonzero row is 1, thus in this case the HNF modulo $p$ agrees with the reduced row echelon form over the field $\Z_p$. In general, the third condition ensures uniqueness in the following theorem.

\begin{theorem}
  If $A$ is an $m\times n$ integer matrix, then there is a unique $m\times n$ integer matrix $B$ with $A\sim B$ and $B$ in row Hermite Normal Form modulo $d$.
\end{theorem}

\begin{definition}
  An integer matrix $A$ is in \emph{Smith Normal Form modulo $d$ (SNF modulo $d$)} if
  \begin{enumerate}
  \item $A=\overline{A}$.
  \item $A$ is in Smith Normal Form.
  \item The nonzero entries of $A$ divide $d$.
  \end{enumerate}
\end{definition}

\begin{theorem}
  If $A$ is an $m\times n$ integer matrix, then there is a unique $m\times n$ integer matrix $B$ with $A\sim B$ and $B$ in Smith Normal Form modulo $d$.
\end{theorem}

The algorithms for computing Hermite and Smith Normal Form modulo an integer are much the same, except all operations are performed modulo $d$, and we multiply rows/columns by appropriate integers $c$ with $\gcd(c,d)=1$ where appropriate to ensure that the relevant entries divide $d$.

\begin{definition}
  Let $A$ be an integer matrix, and let $B$ be the unique matrix in HNF modulo $d$ which is row equivalent modulo $d$ to $A$. The \emph{$d$-rank} of $A$ is the number of nonzero rows of $B$.
\end{definition}

Note that if $A\sim B$ and $B$ is in HNF, then the number of nonzero rows of $B$ is equal to the rank of $A$. Thus the $d$-rank of an integer matrix is a lower bound for its rank.

\begin{definition}
  For an $m\times n$ integer matrix $A$, and $0\leq k\leq m,n$, let $D_k(A)$ denote the gcd of all determinants of $k\times k$ submatrices of $A$. We adopt the convention that the determinant of a $0\times0$ matrix is 1, so that $D_0(A)=1$ for every integer matrix $A$.
\end{definition}

\begin{theorem}
   If integer row or column operations are applied to $A$, then $D_k(A)$ is unchanged for each $0\leq k\leq m,n$.
\end{theorem}

\begin{proof}
  This is clear except when an integer multiple of a row or column is added to another row or column, respectively. See \cite{sims} for the proof.
\end{proof}

\begin{corollary}
  \label{gcdcor}
  Suppose that $A\sim B$, and $B$ is in SNF with invariant factors $d_1\mid d_2\mid\cdots\mid d_r$. Then $D_k(A)=d_1\cdots d_k$ for $k\leq r$, and $D_k(A)=0$ for $k>r$. In particular $d_k=D_k(A)/D_{k-1}(A)$ when $1\leq k\leq r$.
\end{corollary}

This gives an alternate way of computing SNF. Of course, there are $\binom{m}{k}\binom{n}{k}$ different $k\times k$ submatrices of an $m\times n$ matrix, so this quite impractical. However, consider the following.

\begin{theorem}
  \label{recoversnf}
  Let $A$ be an integer matrix, and let $B$ be in SNF with $A\approx B$. Suppose $B$ has invariant factors $d_1\mid d_2\mid \cdots\mid d_r$, and let $d>0$ wtih $d_r\mid d$. Let $C$ be the matrix equivalent to $A$ in SNF modulo $d$. If $C$ has invariant factors $c_1\mid c_2\mid\cdots\mid c_s$, then $s\leq r$, and $d_i=c_i$ for $i\leq s$, and $d_i=d$ for $s<i\leq r$.
\end{theorem}

\begin{proof}
  This follows from noting that $C=\overline{B}$.
\end{proof}

This suggests the following algorithm outline for computing the SNF of a given matrix $A$

\begin{enumerate}
\item Find the rank $r$ of $A$
\item Find a small number of $r\times r$ submatrices of $A$ with nonzero determinant, and take their greatest common divisor $d$. By Corollary \ref{gcdcor}, this will be a multiple of the largest nonzero entry in the SNF of $A$.
\item Compute $C$, the SNF of $A$ modulo $d$
\item If $C$ has $s$ nonzero entries, then by \autoref{recoversnf} we can recover the SNF of $A$ by adding in $r-s$ copies of $d$ on the diagonal after the nonzero entries of $C$.
\end{enumerate}

We do not currently have a method to efficiently compute the rank of a matrix $A$. The HNF algorithm provided earlier also produces relatively large modulus entries for small inputs. We also do not have a method to compute the determinant of an $r\times r$ submatrix of $A$, and find the $r\times r$ submatrices with nonzero determinant.

We can compute the $d$-rank of $A$ by computing the the HNF of $A$ modulo $d$, and this will be a lower bound for the rank of $A$. If we calculate this for various $d$, then their maximum is a lower bound of the rank of $A$. With some work, we can actually ensure that this is equal to the rank.

\begin{theorem}[Hadamard's Inequality]
  Let $A$ be an $n\times n$ real matrix.
  \[ \abs{\det A} \leq \prod_{i=1}^n \left( \sum_{j=1}^n A_{ij}^2 \right)^{1/2} \]
\end{theorem}

\begin{proof}
  See \cite{hadamard}.
\end{proof}

We can use this to get an easily computable bound of the determinant of square submatrix of an $m\times n$ matrix $A$.

\begin{corollary}
  \label{hbound}
  If $A$ is an $m\times n$ integer matrix with $m\leq n$, then the determinant of a square submatrix has modulus at most
  \[ \prod_i \left( \sum_{j=1}^n A_{ij}^2 \right)^{1/2} \text{ and } \left[ \max_j \left( \sum_{i=1}^m A_{ij}^2 \right)^{1/2} \right]^m, \]
  where the product is taken of the nonzero rows.
\end{corollary}

\begin{definition}
  Given an $m\times n$ matrix, we define $h(A)$ to be the bound given by Corollary \ref{hbound} on $A$ if $m\leq n$, and on $A^t$ if $m>n$.
\end{definition}

\begin{theorem}
  Let $A$ be an integer matrix. If $p_1,\ldots,p_k$ are distinct primes with $p_1\cdots p_k>h(A)$, then the rank of $A$ is a the maximum $p_i$-rank of $A$ for $1\leq i\leq k$.
\end{theorem}

\begin{proof}
  Let $r$ be the maximum $p_i$-rank. It suffices to prove that all square submatrices of $A$ with more than $r$ rows have determinant 0. Let $B$ be such a matrix. If $1\leq i\leq k$, since the $p_i$-rank of $A$ is at most $r$, it follows that $\det B\equiv0\pmod{p_i}$. Hence $\det B\equiv0\pmod{p_1\cdots p_k}$. But by Corollary \ref{hbound}, $\abs{\det B}\leq h(A)<p_1\cdots p_k$, thus $\det B=0$.
\end{proof}

Once we have found the rank $r$ of an integer matrix $A$, we can similarly exploit Hadamard's Inequality to efficiently compute the determinants of $r\times r$ submatrices.

\begin{theorem}
  Let $A$ be an integer matrix, and let $B$ be a square submatrix of $A$. Let $p_1,\ldots,p_k$ be distinct primes with $p_1\cdots p_k>2h(A)$. Then if $\det B\equiv b_i\pmod{p_i}$, $1\leq i\leq k$, then $\det B$ is the integer $b$ with smallest absolute value satisfying $b\equiv b_i\pmod{p_i}$, $1\leq i\leq k$.
\end{theorem}

\begin{proof}
  By the Chinese Remainder Theorem, the conditions determine $\det B$ modulo $p_1\cdots p_k$. Also $-h(A)\leq\det B\leq h(A)$, and since $p_1\cdots p_k>2h(A)$, no two integers between $-h(A)$ and $h(A)$ are congruent modulo $p_1\cdots p_k$. 
\end{proof}

Thus we have yet to discuss how to compute the $p$-rank of a matrix, and its determinant modulo $p$, for some prime $p$. However when $p$ is prime, $\Z_p$ is field, so standard methods (e.g. row reduction to row echelon form over a field) can be used to compute the $p$-rank and determinant modulo $p$.

Moreover, \cite{sims} suggests slightly modifying the procedure of row reduction modulo $p$, to find $r\times r$ submatrices of nonzero determinant, where $r$ is the rank. For a matrix $A$ with reduced row echelon form $R$, let $S$ denote the row indices in $A$ which are eventually swapped into a nonzero row position in $R$, and let $T$ denote the column indices which contain the first nonzero entry in some row of $R$. Then the $r\times r$ submatrix of $A$ with rows indexed by $S$ and columns indexed by $T$ will have nonzero determinant.

\section{Empirical Results and Discussion}
\label{conclusion}

Based on the discussions in this report, there are three natural methods available to compute the Smith Normal Form of a given integer matrix in {\sc Magma}. These are
\begin{itemize}
\item \texttt{SmithNormalForm} given in \autoref{snfcode} (described in Section \ref{snf-discussion}), \item \texttt{SmithNormalFormImproved} given in \autoref{snfimprovedcode} (described in Section \ref{modular-discussion}),
\item the {\sc Magma} intrinsic \texttt{SmithForm}.
\end{itemize}

We generated a random $n\times n$ matrix with entries in $\{-1,0,1\}$ for $n=10,20,\ldots,100$, and computed the Smith Normal Form of each of the matrices with each method. The machine used had a clock speed of 2.6GHz, a total of 690GB of RAM, and was running {\sc Magma} version V2.23-3. If a given computation took longer than 30 minutes to halt, it was terminated.

The results of this are recorded in the following table. In each computation, the time taken to compute the SNF, and total memory used in the {\sc Magma} session were recorded. For the computations using \texttt{SmithNormalForm}, the maximum modulus of an entry appearing in some intermediate matrix was recorded (see the ``Max'' column). For the computations using \texttt{SmithNormalFormImproved}, the modulus which calculations were performed with respect to was recorded (see the ``Modulus'' column). There is no corresponding measurement available for the {\sc Magma} intrinsic \texttt{SmithForm}.

  {\centering
  \resizebox{\columnwidth}{!}{%
  \begin{tabular}{|c||c|c|c||c|c|c||c|c|}
    \cline{2-9}
    \multicolumn{1}{c||}{} & \multicolumn{3}{|c||}{\texttt{SmithNormalForm}} & \multicolumn{3}{|c||}{\texttt{SmithNormalFormImproved}} & \multicolumn{2}{|c|}{\texttt{SmithForm}} \\
    \hline
    Dimensions & Time & Memory & Max & Time & Memory & Modulus & Time & Memory \\
    \hline
    $10\times10$ & 0.00s & 32.0MB & 68 & 0.01s & 32.0MB & 40 & 0.00s & 32.0MB \\
    $20\times20$ & 0.00s & 32.0MB & $6.0\cdot10^{42}$ & 0.01s & 32.0MB & $1.7\cdot10^7$ & 0.00s & 32.0MB \\
    $30\times30$ & 0.04s & 32.0MB & $7.8\cdot10^{4056}$ & 0.02s & 32.0MB & $2.5\cdot10^{13}$ & 0.00s & 32.0MB \\
    $40\times40$ & 0.31s & 32.0MB & $\sim10^{1.4\cdot10^5}$ & 0.05s & 32.0MB & $1.3\cdot10^{19}$ & 0.02s & 32.0MB \\
    $50\times50$ & >30m & 384MB & $\sim10^{2.5\cdot10^6}$ & 0.08s & 32.0MB & $3.6\cdot10^{27}$ & 0.02s & 32.0MB \\
    $60\times60$ & >30m & 928MB & $\sim10^{2.5\cdot10^6}$ & 0.15s & 32.0MB & $7.0\cdot10^{34}$ & 0.02s & 32.0MB \\
    $70\times70$ & >30m & 2.89GB & $\sim10^{5.4\cdot10^6}$ & 0.24s & 32.0MB & $5.0\cdot10^{42}$ & 0.02s & 32.0MB \\
    $80\times80$ & >30m & 25.0GB & $\sim10^{1.2\cdot10^7}$ & 0.38s & 32.0MB & $2.0\cdot10^{51}$ & 0.03s & 32.0MB \\
    $90\times90$ & >30m & 2.56GB & $\sim10^{8.9\cdot10^5}$ & 0.60s & 64.0MB & $1.9\cdot10^{60}$ & 0.07s & 32.0MB \\
    $100\times100$ & >30m & 14.8GB & $\sim10^{2.3\cdot10^6}$ & 0.79s & 64.0MB & $1.6\cdot10^{58}$ & 0.06s & 32.0MB \\
    \hline
  \end{tabular}%
  }}\newline


\texttt{SmithNormalFormImproved} outperforms the original procedure \texttt{SmithNormalForm} only when the dimensions of the input are sufficiently large. This is because some extra computation, e.g. the bound given by Corollary \ref{hbound}, is performed by \texttt{SmithNormalFormImproved}. The cost of these additional calculations are only outweighed by the benefit of performing row operations with respect to an appropriate modulus, when the entries appearing in intermediate matrices are very large, which occurs when the input dimensions are large.

Observe that the {\sc Magma} intrinsic \texttt{SmithForm} always performs better than the procedure \texttt{SmithNormalFormImproved}. One reason for this is \texttt{SmithForm} is a compiled C program, however \texttt{SmithNormalFormImproved} is written in {\sc Magma}, an interpreted language.

Moreover, there are other techniques beyond those discussed in \autoref{modular-discussion} which can be used to more efficiently compute the SNF, many of which are discussed in \cite{havas}. Recall the beginning of the proof of \autoref{SNF-existence}, in which a nonzero entry which divided every term in its row and column was needed. If one did not exist, then by choosing a nonzero entry we could produce a smaller entry by applying some row and column operations.

In \cite{havas}, this process is called \emph{pivoting}, and the nonzero entry which is selected is called a \emph{pivot}. In \texttt{SmithNormalForm}, the way a pivot is selected is to initially choose the smallest modulus entry, and thereafter select the first entry in the current pivot's row and column which is not divisible by the current pivot. \cite{havas} suggests some alternate pivoting strategies which can improve performance. In particular it is recommended to try certain pivoting strategies first, and only resort to modular methods if these are unsuccessful.

There is a final deficiency in both of the procedures described in this report. Given an $m\times n$ integer matrix $A$, computing the SNF of $A$ determines the rank $r$ and positive integers $d_1\mid d_2\mid\cdots\mid d_r$ such that $\Z^n/S(A) \cong \Z_{d_1}\oplus\cdots\oplus\Z_{d_r}\oplus\Z^{n-r}$. However the SNF alone does not provide an explicit description of such isomorphism, which is often useful.

When only row and column operations and no modular techniques are used to compute the SNF of $A$, we can find $P\in\GL_m(\Z)$, $Q\in\GL_n(\Z)$ such that $PAQ$ is in SNF, by applying the row operations to $I_m$ to produce $P$, and the column operations to $I_n$ to produce $Q$. As in the proof of \autoref{commutative-diagram}, $P$ and $Q$ can be used to describe such an isomorphism.

Unfortunately, when modular techniques are applied, such an isomorphism can only be recovered in this way if $r=n$. If we define $T\coloneqq\Z_{d_1}\oplus\cdots\oplus\Z_{d_r}$ and $F\coloneqq\Z^{n-r}$, then $\Z^n/S(A)\cong T\oplus F$, and $T$ is torsion (every element has finite order), and $\Z^{n-r}$ is torsion free (all non-identity elements have infinite order). \cite{havas} describes how \emph{Lattice Basis Reduction} algorithms such as {\sc mlll} can be used together with the modular methods described here, to completely describe an isomorphism $\Z^n/S(A)\to T\oplus F$.

\printbibliography
  
\appendix

\section{Hermite Normal Form}

\label{hnfcode}

\lstinputlisting[language=magma,tabsize=8]{../magma/RowReduce.m}

\section{Smith Normal Form}

\label{snfcode}

\lstinputlisting[language=magma,tabsize=8]{../magma/SmithNormalForm.m}

\section{Smith Normal Form Improved}

\label{snfimprovedcode}

\lstinputlisting[language=magma,tabsize=8]{../magma/SNFImproved.m}

\end{document}
